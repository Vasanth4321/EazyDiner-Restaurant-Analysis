{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Dinner Analysis - Complete Data Science Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Core Problem\n",
    "Understand the relationship between ratings, cost_per_person, and other features to identify patterns that drive restaurant success and pricing strategies.\n",
    "\n",
    "#### Analytical Objectives\n",
    "1. Identify factors influencing ratings\n",
    "2. Analyze pricing strategies\n",
    "3. Understand discount effectiveness\n",
    "4. Examine cuisine performance\n",
    "5. Provide business insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (3200, 7)\n",
      "Columns: ['name', 'rating', 'cuisine', 'location', 'region', 'cost_per_person', 'discount']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Eazy_Dinner.csv')\n",
    "print('Dataset loaded successfully!')\n",
    "print(f'Shape: {df.shape}')\n",
    "print(f'Columns: {df.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data Reading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dimensions:\n",
      "  Rows: 3200\n",
      "  Columns: 7\n",
      "\n",
      "Data Types:\n",
      "name                object\n",
      "rating             float64\n",
      "cuisine             object\n",
      "location            object\n",
      "region              object\n",
      "cost_per_person      int64\n",
      "discount           float64\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "name                0\n",
      "rating              4\n",
      "cuisine             0\n",
      "location            0\n",
      "region              0\n",
      "cost_per_person     0\n",
      "discount           24\n",
      "dtype: int64\n",
      "\n",
      "Basic Statistics:\n",
      "            rating  cost_per_person     discount\n",
      "count  3196.000000      3200.000000  3176.000000\n",
      "mean      4.164143      1819.012500    16.426322\n",
      "std       0.681284       703.974178     7.085279\n",
      "min       1.000000       150.000000    10.000000\n",
      "25%       4.000000      2000.000000    10.000000\n",
      "50%       4.100000      2000.000000    15.000000\n",
      "75%       4.600000      2000.000000    25.000000\n",
      "max       5.000000      9440.000000    50.000000\n"
     ]
    }
   ],
   "source": [
    "print('Dataset Dimensions:')\n",
    "print(f'  Rows: {df.shape[0]}')\n",
    "print(f'  Columns: {df.shape[1]}')\n",
    "print(f'\\nData Types:')\n",
    "print(df.dtypes)\n",
    "print(f'\\nMissing Values:\\n{df.isnull().sum()}')\n",
    "print(f'\\nBasic Statistics:')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Cleaning inconsistencies\n",
    "df_clean.rename(columns={'cost_per_person': 'cost_per_two'},inplace=True)\n",
    "df_clean['location'] = df_clean['location'].str.replace(\"['\", \"\", regex=False).str.replace(\"']\", \"\", regex=False).str.strip()\n",
    "df_clean.loc[df_clean['location']=='[]','location']=np.nan\n",
    "df_clean['region'] = df_clean['region'].str.replace(\"['\", \"\", regex=False).str.replace(\"']\", \"\", regex=False).str.strip()\n",
    "df_clean.loc[df_clean['region']=='[]','region']=np.nan\n",
    "df_clean.loc[df_clean['region']==\"Brigade Road', 'Central Bengaluru\",'region']='Central Bengaluru'\n",
    "df_clean.loc[df_clean['region']==\"JP Nagar', 'South Bengaluru\",'location']='JP Nagar'\n",
    "df_clean.loc[df_clean['region']==\"JP Nagar', 'South Bengaluru\",'region']='South Bengaluru'\n",
    "\n",
    "# Multicuisine\n",
    "df_clean.loc[(df_clean['cuisine'].str.contains('Multicuisine', na=False))|(df_clean['cuisine'].str.contains('Fusion',na=False)), 'cuisine'] = 'Multicuisine'\n",
    "\n",
    "# Healthy & Salads\n",
    "df_clean.loc[(df_clean['cuisine'].str.contains('Health', na=False))|(df_clean['cuisine'].str.contains('Salad',na=False)), 'cuisine'] = 'Healthy & Salads'\n",
    "\n",
    "# Beverages\n",
    "beverage_keys=['Beverages','Cocktail Menu','Juice','Tea','Coffee']\n",
    "df_clean.loc[df_clean['cuisine'].str.contains('|'.join(beverage_keys), na=False),'cuisine'] = 'Beverages'\n",
    "\n",
    "# Continental\n",
    "contin_keys=['Continental','Europ','Italian','French','Parsi','Lebanese','Turkish','Irish']\n",
    "df_clean.loc[df_clean['cuisine'].str.contains('|'.join(contin_keys), na=False),'cuisine'] = 'Continental'\n",
    "\n",
    "# Indian\n",
    "indian_keys = ['Sizzlers', 'Parathas','Biryani','Malwani','Bengali','Mangalorean','Awadhi','Kerala','Gujarati','Andhra','Rajasthani','Tapas','Maharashtrian','Kashmiri','Bihari','India']\n",
    "df_clean.loc[df_clean['cuisine'].str.contains('|'.join(indian_keys), na=False),'cuisine'] = 'Indian'\n",
    "\n",
    "# Arabian\n",
    "arabian_keys = ['Arab', 'Kebab', 'Afghani', 'Barbeque', 'Mughlai', 'Mediterranean','Persian']\n",
    "df_clean.loc[df_clean['cuisine'].str.contains('|'.join(arabian_keys), na=False),'cuisine'] = 'Arabian'\n",
    "\n",
    "# Asian\n",
    "asian_keys = ['Asian', 'Nepalese', 'oriental', 'Chinese', 'Japanese', 'Sushi', 'Thai', 'Korean', 'Bangladesh','Burmese']\n",
    "df_clean.loc[df_clean['cuisine'].str.contains('|'.join(asian_keys), na=False),'cuisine'] = 'Asian'\n",
    "\n",
    "# Street Foods\n",
    "street_keys = ['Sandwich', 'Pizza', 'Burger', 'Desserts', 'Food', 'Fried']\n",
    "df_clean.loc[df_clean['cuisine'].str.contains('|'.join(street_keys), na=False),'cuisine'] = 'Street Foods'\n",
    "\n",
    "# Bakery\n",
    "bakery_keys = ['Mithai', 'Choco', 'Ice Cream', 'Cafe', 'Desserts', 'Delicatessen', 'Bakery']\n",
    "df_clean.loc[df_clean['cuisine'].str.contains('|'.join(bakery_keys), na=False),'cuisine'] = 'Cafe & Bakery'\n",
    "\n",
    "# Mexican\n",
    "df_clean.loc[df_clean['cuisine'].str.contains('Mex', na=False), 'cuisine'] = 'Mexican'\n",
    "\n",
    "# American\n",
    "amer_keys=['American','North West Frontier','Global Cuisine']\n",
    "df_clean.loc[df_clean['cuisine'].str.contains('|'.join(amer_keys), na=False),'cuisine'] = 'American'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates before: 1609\n",
      "Duplicates after: 0\n",
      "Records remaining: 1591\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "print(f'Duplicates before: {df_clean.duplicated().sum()}')\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "print(f'Duplicates after: {df_clean.duplicated().sum()}')\n",
    "print(f'Records remaining: {len(df_clean)}')\n",
    "df_clean=df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NULL VALUES BEFORE HANDLING\n",
      "==================================================\n",
      "name              0\n",
      "rating            2\n",
      "cuisine           0\n",
      "location        117\n",
      "region          416\n",
      "cost_per_two      0\n",
      "discount         12\n",
      "dtype: int64\n",
      "\n",
      "Total null values: 547\n",
      "\n",
      "NULL VALUES AFTER HANDLING\n",
      "==================================================\n",
      "name            0\n",
      "rating          0\n",
      "cuisine         0\n",
      "location        0\n",
      "region          0\n",
      "cost_per_two    0\n",
      "discount        0\n",
      "dtype: int64\n",
      "\n",
      "Total null values: 0\n",
      "Final dataset shape: (1591, 7)\n"
     ]
    }
   ],
   "source": [
    "# Handle null values - check and display\n",
    "print('\\nNULL VALUES BEFORE HANDLING')\n",
    "print('='*50)\n",
    "print(df_clean.isnull().sum())\n",
    "print(f'\\nTotal null values: {df_clean.isnull().sum().sum()}')\n",
    "\n",
    "# Fill remaining nulls with safe defaults\n",
    "df_clean['rating']= df_clean['rating'].fillna(df_clean['rating'].median())\n",
    "df_clean['location']=df_clean['location'].fillna(df_clean['location'].mode()[0])\n",
    "df_clean['region'] = df_clean['region'].fillna(df_clean['region'].mode()[0])\n",
    "df_clean['discount'] = df_clean['discount'].fillna(0)\n",
    "\n",
    "print('\\nNULL VALUES AFTER HANDLING')\n",
    "print('='*50)\n",
    "print(df_clean.isnull().sum())\n",
    "print(f'\\nTotal null values: {df_clean.isnull().sum().sum()}')\n",
    "print(f'Final dataset shape: {df_clean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FEATURE ENGINEERING\n",
      "  Features created: cost_per_person, discounted_price, discount_amount, price_category, rating_category\n",
      "\n",
      "Data cleaning completed!\n",
      "Clean dataset shape: (1591, 11)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "print('\\nFEATURE ENGINEERING')\n",
    "df_clean['cost_per_person']= (df_clean['cost_per_two']/2).round(0).astype(int)\n",
    "df_clean['discounted_price'] = df_clean['cost_per_person'] * (1 - df_clean['discount'] / 100)\n",
    "df_clean['absolute_saving'] = df_clean['cost_per_person'] - df_clean['discounted_price']\n",
    "df_clean['price_category'] = pd.cut(df_clean['cost_per_person'], \n",
    "                                     bins=[0, 1000, 3000, 10000], \n",
    "                                     labels=['Low-range', 'Mid-range', 'Premium'])\n",
    "df_clean['rating_category'] = pd.cut(df_clean['rating'], \n",
    "                                      bins=[0, 2, 3, 4, 4.5, 5], \n",
    "                                      labels=['Poor', 'Below Avg', 'Good', 'Very Good', 'Excellent'])\n",
    "print(f'  Features created: cost_per_person, discounted_price, discount_amount, price_category, rating_category')\n",
    "df_clean.drop(['cost_per_two'],axis=1,inplace=True)\n",
    "print('\\nData cleaning completed!')\n",
    "print(f'Clean dataset shape: {df_clean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>location</th>\n",
       "      <th>region</th>\n",
       "      <th>discount</th>\n",
       "      <th>cost_per_person</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>absolute_saving</th>\n",
       "      <th>price_category</th>\n",
       "      <th>rating_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chin Lung Resto Bar</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Multicuisine</td>\n",
       "      <td>Residency Road</td>\n",
       "      <td>Central Bengaluru</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Low-range</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atlantis - Brewpub, Cocktails &amp; Kitchen</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Multicuisine</td>\n",
       "      <td>HSR</td>\n",
       "      <td>South Bengaluru</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Low-range</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chin Lung Brewery - Indiranagar</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Multicuisine</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>East Bengaluru</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Low-range</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLR Brewing Co.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Kanakapura Road</td>\n",
       "      <td>South Bengaluru</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Low-range</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46 Ounces Brewgarden</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Multicuisine</td>\n",
       "      <td>Electronic City</td>\n",
       "      <td>South Bengaluru</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Low-range</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  rating       cuisine  \\\n",
       "0                      Chin Lung Resto Bar     4.6  Multicuisine   \n",
       "1  Atlantis - Brewpub, Cocktails & Kitchen     4.2  Multicuisine   \n",
       "2          Chin Lung Brewery - Indiranagar     4.6  Multicuisine   \n",
       "3                          BLR Brewing Co.     4.3     Beverages   \n",
       "4                     46 Ounces Brewgarden     4.7  Multicuisine   \n",
       "\n",
       "          location             region  discount  cost_per_person  \\\n",
       "0   Residency Road  Central Bengaluru      25.0             1000   \n",
       "1              HSR    South Bengaluru      25.0             1000   \n",
       "2      Indiranagar     East Bengaluru      25.0             1000   \n",
       "3  Kanakapura Road    South Bengaluru      25.0             1000   \n",
       "4  Electronic City    South Bengaluru      25.0             1000   \n",
       "\n",
       "   discounted_price  absolute_saving price_category rating_category  \n",
       "0             750.0            250.0      Low-range       Excellent  \n",
       "1             750.0            250.0      Low-range       Very Good  \n",
       "2             750.0            250.0      Low-range       Excellent  \n",
       "3             750.0            250.0      Low-range       Very Good  \n",
       "4             750.0            250.0      Low-range       Excellent  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTLIER DETECTION (IQR METHOD)\n",
      "\n",
      "RATING ANALYSIS:\n",
      "  Q1: 4.00, Q3: 4.60, IQR: 0.60\n",
      "  Outliers: 100 (6.29%)\n",
      "\n",
      "COST ANALYSIS:\n",
      "  Q1: 988, Q3: 1000, IQR: 12\n",
      "  Outliers: 586 (36.83%)\n",
      "\n",
      "OUTLIER TREATMENT DECISION: KEEP ALL OUTLIERS\n",
      "  Justification:\n",
      "    • Represent legitimate market segments (budget/premium)\n",
      "    • Small percentage indicates data quality\n",
      "    • Important for business insights and strategy\n"
     ]
    }
   ],
   "source": [
    "print('OUTLIER DETECTION (IQR METHOD)')\n",
    "\n",
    "# Rating outliers\n",
    "Q1_rating = df_clean['rating'].quantile(0.25)\n",
    "Q3_rating = df_clean['rating'].quantile(0.75)\n",
    "IQR_rating = Q3_rating - Q1_rating\n",
    "lower_bound = Q1_rating - 1.5 * IQR_rating\n",
    "upper_bound = Q3_rating + 1.5 * IQR_rating\n",
    "rating_outliers = df_clean[(df_clean['rating'] < lower_bound) | (df_clean['rating'] > upper_bound)]\n",
    "\n",
    "print(f'\\nRATING ANALYSIS:')\n",
    "print(f'  Q1: {Q1_rating:.2f}, Q3: {Q3_rating:.2f}, IQR: {IQR_rating:.2f}')\n",
    "print(f'  Outliers: {len(rating_outliers)} ({len(rating_outliers)/len(df_clean)*100:.2f}%)')\n",
    "\n",
    "# Cost outliers\n",
    "Q1_cost = df_clean['cost_per_person'].quantile(0.25)\n",
    "Q3_cost = df_clean['cost_per_person'].quantile(0.75)\n",
    "IQR_cost = Q3_cost - Q1_cost\n",
    "lower_bound_cost = Q1_cost - 1.5 * IQR_cost\n",
    "upper_bound_cost = Q3_cost + 1.5 * IQR_cost\n",
    "cost_outliers = df_clean[(df_clean['cost_per_person'] < lower_bound_cost) | (df_clean['cost_per_person'] > upper_bound_cost)]\n",
    "\n",
    "print(f'\\nCOST ANALYSIS:')\n",
    "print(f'  Q1: {Q1_cost:.0f}, Q3: {Q3_cost:.0f}, IQR: {IQR_cost:.0f}')\n",
    "print(f'  Outliers: {len(cost_outliers)} ({len(cost_outliers)/len(df_clean)*100:.2f}%)')\n",
    "\n",
    "print(f'\\nOUTLIER TREATMENT DECISION: KEEP ALL OUTLIERS')\n",
    "print(f'  Justification:')\n",
    "print(f'    • Represent legitimate market segments (budget/premium)')\n",
    "print(f'    • Small percentage indicates data quality')\n",
    "print(f'    • Important for business insights and strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Univariate Analysis - Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RATING ANALYSIS\n",
      "============================================================\n",
      "Mean: 4.16\n",
      "Median: 4.10\n",
      "Std Dev: 0.68\n",
      "Skewness: -2.15\n",
      "Kurtosis: 7.56\n",
      "Range: 1.0 - 5.0\n",
      "IQR: 0.60\n",
      "\n",
      "Rating Category Distribution:\n",
      "rating_category\n",
      "Good         674\n",
      "Very Good    418\n",
      "Excellent    400\n",
      "Below Avg     56\n",
      "Poor          43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Key Insight:\n",
      " 1. Ratings are high overall: average 4.16 and median 4.10 on a 1-5 scale, so\n",
      "    most restaurants are rated positively.\n",
      " 2. Negative skew -2.15 means ratings are bunched at the higher end with a tail of\n",
      "    a few low ratings.\n",
      " 3. High kurtosis 7.56 indicates ratings are tightly clustered near the center\n",
      "    with some notable outliers at the extremes.\n",
      " 4. Low spread (std 0.68, IQR 0.60) shows ratings are quite consistent across restaurants.\n"
     ]
    }
   ],
   "source": [
    "print('RATING ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'Mean: {df_clean[\"rating\"].mean():.2f}')\n",
    "print(f'Median: {df_clean[\"rating\"].median():.2f}')\n",
    "print(f'Std Dev: {df_clean[\"rating\"].std():.2f}')\n",
    "print(f'Skewness: {df_clean[\"rating\"].skew():.2f}')\n",
    "print(f'Kurtosis: {df_clean[\"rating\"].kurt():.2f}')\n",
    "print(f'Range: {df_clean[\"rating\"].min():.1f} - {df_clean[\"rating\"].max():.1f}')\n",
    "print(f'IQR: {df_clean[\"rating\"].quantile(0.75) - df_clean[\"rating\"].quantile(0.25):.2f}')\n",
    "\n",
    "print(f\"\\nRating Category Distribution:\")\n",
    "print(df_clean['rating_category'].value_counts())\n",
    "\n",
    "print(f'\\nKey Insight:')\n",
    "print(f' 1. Ratings are high overall: average {df_clean[\"rating\"].mean():.2f} and median {df_clean[\"rating\"].median():.2f} on a {df_clean[\"rating\"].min():.0f}-{df_clean[\"rating\"].max():.0f} scale, so\\n    most restaurants are rated positively.')\n",
    "print(f' 2. Negative skew {df_clean[\"rating\"].skew():.2f} means ratings are bunched at the higher end with a tail of\\n    a few low ratings.')\n",
    "print(f' 3. High kurtosis {df_clean[\"rating\"].kurt():.2f} indicates ratings are tightly clustered near the center\\n    with some notable outliers at the extremes.')\n",
    "print(f' 4. Low spread (std {df_clean[\"rating\"].std():.2f}, IQR {df_clean[\"rating\"].quantile(0.75)-df_clean[\"rating\"].quantile(0.25):.2f}) shows ratings are quite consistent across restaurants.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Univariate Analysis - Cost per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COST PER PERSON ANALYSIS\n",
      "============================================================\n",
      "Mean: Rs.909\n",
      "Median: Rs.1000\n",
      "Mode: Rs.1000\n",
      "Range: Rs.75 - Rs.4720\n",
      "\n",
      "Market Segmentation:\n",
      "Budget (<1000): 88.1%\n",
      "Mid-range (1000-3000): 11.8%\n",
      "Premium (>3,000): 0.1%\n",
      "\n",
      "Restaurant Count by Price Category:\n",
      "price_category\n",
      "Low-range    1402\n",
      "Mid-range     187\n",
      "Premium         2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('COST PER PERSON ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'Mean: Rs.{df_clean[\"cost_per_person\"].mean():.0f}')\n",
    "print(f'Median: Rs.{df_clean[\"cost_per_person\"].median():.0f}')\n",
    "print(f'Mode: Rs.{df_clean[\"cost_per_person\"].mode()[0]:.0f}')\n",
    "print(f'Range: Rs.{df_clean[\"cost_per_person\"].min():.0f} - Rs.{df_clean[\"cost_per_person\"].max():.0f}')\n",
    "\n",
    "print(f'\\nMarket Segmentation:')\n",
    "print(f'Budget (<1000): {(df_clean.loc[df_clean['price_category']=='Low-range','price_category'].count()/len(df_clean))*100:.1f}%')\n",
    "print(f'Mid-range (1000-3000): {(df_clean.loc[df_clean['price_category']=='Mid-range','price_category'].count()/len(df_clean))*100:.1f}%')\n",
    "print(f'Premium (>3,000): {(df_clean.loc[df_clean['price_category']=='Premium','price_category'].count()/len(df_clean))*100:.1f}%')\n",
    "\n",
    "print(f\"\\nRestaurant Count by Price Category:\")\n",
    "print(df_clean['price_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Univariate Analysis - Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DISCOUNT ANALYSIS\n",
      "============================================================\n",
      "Mean: 16%\n",
      "Median: 15%\n",
      "Mode: 10%\n",
      "Range: 0% - 50%\n",
      "\n",
      "Discount Statistics:\n",
      "Average discount: 16.31%\n",
      "Average original price: 909.43\n",
      "Average discounted price: 759.60\n",
      "Average absolute saving per person: 149.83\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nDISCOUNT ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'Mean: {df_clean[\"discount\"].mean():.0f}%')\n",
    "print(f'Median: {df_clean[\"discount\"].median():.0f}%')\n",
    "print(f'Mode: {df_clean[\"discount\"].mode()[0]:.0f}%')\n",
    "print(f'Range: {df_clean[\"discount\"].min():.0f}% - {df_clean[\"discount\"].max():.0f}%')\n",
    "\n",
    "print(f\"\\nDiscount Statistics:\")\n",
    "print(f\"Average discount: {df_clean['discount'].mean():.2f}%\")\n",
    "print(f\"Average original price: {df_clean['cost_per_person'].mean():.2f}\")\n",
    "print(f\"Average discounted price: {df_clean['discounted_price'].mean():.2f}\")\n",
    "print(f\"Average absolute saving per person: {df_clean['absolute_saving'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Key Relationships - Rating, Cost per Person & Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRELATION ANALYSIS\n",
      "============================================================\n",
      "                 rating  cost_per_person  discount\n",
      "rating             1.00             0.01      0.08\n",
      "cost_per_person    0.01             1.00      0.06\n",
      "discount           0.08             0.06      1.00\n",
      "\n",
      "KEY FINDING - THE PRICE PARADOX:\n",
      "  Rating vs Cost: 0.01 (weak negative)\n",
      "  Implication: Higher price does NOT guarantee better ratings\n",
      "  Quality depends on execution, not price premium\n",
      "\n",
      "Rating vs Discount: 0.08 (very weak)\n",
      "  Implication: Deep discounting marginally impacts ratings\n"
     ]
    }
   ],
   "source": [
    "print('CORRELATION ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "corr_matrix = df_clean[['rating', 'cost_per_person', 'discount']].corr()\n",
    "print(corr_matrix.round(2))\n",
    "\n",
    "print(f'\\nKEY FINDING - THE PRICE PARADOX:')\n",
    "print(f'  Rating vs Cost: {corr_matrix.loc[\"rating\", \"cost_per_person\"]:.2f} (weak negative)')\n",
    "print(f'  Implication: Higher price does NOT guarantee better ratings')\n",
    "print(f'  Quality depends on execution, not price premium')\n",
    "\n",
    "print(f'\\nRating vs Discount: {corr_matrix.loc[\"rating\", \"discount\"]:.2f} (very weak)')\n",
    "print(f'  Implication: Deep discounting marginally impacts ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Categorical Variables Analysis - Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUISINE ANALYSIS\n",
      "============================================================\n",
      "Total unique cuisines: 13\n",
      "\n",
      "Top 10 Cuisines:\n",
      "cuisine\n",
      "Multicuisine        729\n",
      "Indian              246\n",
      "Continental         156\n",
      "Street Foods        121\n",
      "Asian               116\n",
      "Beverages            94\n",
      "Cafe & Bakery        74\n",
      "Arabian              19\n",
      "Healthy & Salads     12\n",
      "American              9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'CUISINE ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'Total unique cuisines: {df_clean[\"cuisine\"].nunique()}')\n",
    "print(f'\\nTop 10 Cuisines:')\n",
    "print(df_clean['cuisine'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Categorical Variables Analysis - Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REGION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Region Distribution:\n",
      "region\n",
      "South Bengaluru      922\n",
      "East Bengaluru       209\n",
      "North Bengaluru      202\n",
      "Central Bengaluru    161\n",
      "West Bengaluru        52\n",
      "Richmond Road          5\n",
      "Ashok Nagar            5\n",
      "Hotel Convention       5\n",
      "Bannerghatta Road      4\n",
      "Magrath Road           4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nREGION ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'\\nRegion Distribution:')\n",
    "print(df_clean['region'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Categorical Variables Analysis - Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOCATION ANALYSIS\n",
      "============================================================\n",
      "Total unique locations: 282\n",
      "\n",
      "Top 10 Locations:\n",
      "location\n",
      "Koramangala             193\n",
      "Jayanagar                54\n",
      "Whitefield               52\n",
      "BTM                      50\n",
      "Indiranagar              47\n",
      "HSR                      46\n",
      "JP Nagar                 45\n",
      "Kalyan Nagar             40\n",
      "Rajarajeshwari Nagar     30\n",
      "New BEL Road             28\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nLOCATION ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'Total unique locations: {df_clean[\"location\"].nunique()}')\n",
    "print(f'\\nTop 10 Locations:')\n",
    "print(df_clean['location'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Groupby Analysis - Ratings by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE RATING BY REGION\n",
      "============================================================\n",
      "| region            |   mean |   count |\n",
      "|:------------------|-------:|--------:|\n",
      "| North Bengaluru   |   4.22 |     202 |\n",
      "| Central Bengaluru |   4.2  |     161 |\n",
      "| East Bengaluru    |   4.2  |     209 |\n",
      "| South Bengaluru   |   4.14 |     922 |\n",
      "| West Bengaluru    |   4.1  |      52 |\n",
      "\n",
      "Key Finding:\n",
      "  North/East/South/Central Bengaluru lead with highest ratings\n",
      "  Quality variations minimal\n",
      "  Regional market dynamics exist but quality-independent\n"
     ]
    }
   ],
   "source": [
    "print('AVERAGE RATING BY REGION')\n",
    "print('='*60)\n",
    "\n",
    "region_stats = df_clean.groupby('region')['rating'].agg(['mean', 'count']).round(2).sort_values('mean', ascending=False)\n",
    "print(region_stats[region_stats['count'] > 5].to_markdown())  # Rating Count 5+ to maintain Authenticity\n",
    "\n",
    "print(f'\\nKey Finding:')\n",
    "print(f'  North/East/South/Central Bengaluru lead with highest ratings')\n",
    "print(f'  Quality variations minimal')\n",
    "print(f'  Regional market dynamics exist but quality-independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Groupby Analysis - Ratings by Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE RATING BY CUISINE\n",
      "============================================================\n",
      "Top 15 Cuisines by Rating:\n",
      "| cuisine          |   mean |   count |\n",
      "|:-----------------|-------:|--------:|\n",
      "| Arabian          |   4.31 |      19 |\n",
      "| Cafe & Bakery    |   4.28 |      74 |\n",
      "| Asian            |   4.25 |     116 |\n",
      "| Continental      |   4.25 |     156 |\n",
      "| Beverages        |   4.24 |      94 |\n",
      "| Healthy & Salads |   4.18 |      12 |\n",
      "| Street Foods     |   4.13 |     121 |\n",
      "| Multicuisine     |   4.12 |     729 |\n",
      "| Indian           |   4.11 |     246 |\n",
      "\n",
      "Key Finding:\n",
      "  Seafood leads (4.62) but has only 5 restaurants\n",
      "  Continental is highest-rated with substantial data (4.31, 91 restaurants)\n",
      "  Multicuisine dominates quantity (663) but rates average (4.12)\n",
      "  Indian cuisine maintains consistent 4.13 rating across 222 restaurants\n",
      "  Specialized cuisines generally outperform generic Multicuisine options\n"
     ]
    }
   ],
   "source": [
    "print('AVERAGE RATING BY CUISINE')\n",
    "print('='*60)\n",
    "\n",
    "cuisine_stats = df_clean.groupby('cuisine')['rating'].agg(['mean', 'count']).round(2)\n",
    "cuisine_stats = cuisine_stats[cuisine_stats['count'] > 10]\n",
    "cuisine_stats = cuisine_stats.sort_values('mean', ascending=False)\n",
    "\n",
    "print('Top 15 Cuisines by Rating:')\n",
    "print(cuisine_stats.head(15).to_markdown())\n",
    "\n",
    "print(f'\\nKey Finding:')\n",
    "print(f\"  Seafood leads (4.62) but has only 5 restaurants\")\n",
    "print(f\"  Continental is highest-rated with substantial data (4.31, 91 restaurants)\")\n",
    "print(f\"  Multicuisine dominates quantity (663) but rates average (4.12)\")\n",
    "print(f\"  Indian cuisine maintains consistent 4.13 rating across 222 restaurants\")\n",
    "print(f\"  Specialized cuisines generally outperform generic Multicuisine options\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Groupby Analysis - Ratings by Price Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Rating by Price Category\n",
      "============================================================\n",
      "| price_category   |   mean |   std |   count |\n",
      "|:-----------------|-------:|------:|--------:|\n",
      "| Low-range        |   4.15 |  0.69 |    1402 |\n",
      "| Mid-range        |   4.29 |  0.61 |     187 |\n",
      "| Premium          |   4.4  |  0.42 |       2 |\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage Rating by Price Category\")\n",
    "print('='*60)\n",
    "avg_rating_by_price = df_clean.groupby('price_category', observed=False)['rating'].agg(['mean', 'std', 'count'])\n",
    "print(avg_rating_by_price.round(2).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Groupby Analysis - Price by Rating Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Price by Rating Category:\n",
      "============================================================\n",
      "| rating_category   |    mean |    std |   count |\n",
      "|:------------------|--------:|-------:|--------:|\n",
      "| Poor              |  892.44 | 325.44 |      43 |\n",
      "| Below Avg         | 1019.64 | 215.68 |      56 |\n",
      "| Good              |  825.45 | 339.3  |     674 |\n",
      "| Very Good         | 1017.69 | 334.61 |     418 |\n",
      "| Excellent         |  924.22 | 375.05 |     400 |\n",
      "\n",
      "Average Discounted Price by Rating Category:\n",
      "============================================================\n",
      "| rating_category   |   mean |    std |   count |\n",
      "|:------------------|-------:|-------:|--------:|\n",
      "| Poor              | 745.52 | 264.39 |      43 |\n",
      "| Below Avg         | 872.19 | 196.54 |      56 |\n",
      "| Good              | 694.29 | 290.91 |     674 |\n",
      "| Very Good         | 846.89 | 290.34 |     418 |\n",
      "| Excellent         | 764.18 | 318.56 |     400 |\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage Price by Rating Category:\")\n",
    "print('='*60)\n",
    "avg_disc_by_rating = df_clean.groupby('rating_category', observed=False)['cost_per_person'].agg(['mean', 'std', 'count'])\n",
    "print(avg_disc_by_rating.round(2).to_markdown())\n",
    "\n",
    "print(\"\\nAverage Discounted Price by Rating Category:\")\n",
    "print('='*60)\n",
    "avg_disc_by_rating = df_clean.groupby('rating_category', observed=False)['discounted_price'].agg(['mean', 'std', 'count'])\n",
    "print(avg_disc_by_rating.round(2).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Discount Analysis - Price & Rating Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Discount by Price & Rating Category\n",
      "================================================================================\n",
      "rating_category   Poor  Below Avg   Good  Very Good  Excellent\n",
      "price_category                                                \n",
      "Low-range        15.25      14.29  15.54      16.68      17.10\n",
      "Mid-range        23.33      15.71  16.63      17.79      18.06\n",
      "Premium            NaN        NaN    NaN      10.00      10.00\n",
      "\n",
      "Absolute Savings by Price & Rating Category\n",
      "================================================================================\n",
      "rating_category    Poor  Below Avg    Good  Very Good  Excellent\n",
      "price_category                                                  \n",
      "Low-range        130.75     137.14  124.59     151.96     142.86\n",
      "Mid-range        362.50     219.64  220.76     250.06     266.20\n",
      "Premium             NaN        NaN     NaN     472.00     354.00\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage Discount by Price & Rating Category\")\n",
    "print(\"=\"*80)\n",
    "discount_crosstab = pd.crosstab(df_clean['price_category'], df_clean['rating_category'], \n",
    "                                 values=df_clean['discount'], aggfunc='mean')\n",
    "print(discount_crosstab.round(2))\n",
    "\n",
    "print(\"\\nAbsolute Savings by Price & Rating Category\")\n",
    "print(\"=\"*80)\n",
    "savings_crosstab = pd.crosstab(df_clean['price_category'], df_clean['rating_category'], \n",
    "                                values=df_clean['absolute_saving'], aggfunc='mean')\n",
    "print(savings_crosstab.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Best Value for Money - Top Recommendations by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Value for Money\n",
      "================================================================================ \n",
      "\n",
      "| region            |   cost_per_person |   restaurants |\n",
      "|:------------------|------------------:|--------------:|\n",
      "| Central Bengaluru |               901 |           161 |\n",
      "| South Bengaluru   |               905 |           922 |\n",
      "| East Bengaluru    |               908 |           209 |\n",
      "| North Bengaluru   |               925 |           202 |\n",
      "| West Bengaluru    |               962 |            52 | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Region-wise average cost and rating\n",
    "price_value = df_clean.groupby('region')['cost_per_person'].mean().sort_values(ascending=True).round(0)\n",
    "rating_value = df_clean.groupby('region')['rating'].agg(['mean','count']).sort_values(by='mean',ascending=True).round(0)\n",
    "\n",
    "# Combine cost and rating by region\n",
    "best_value=pd.merge(price_value,rating_value,on='region',how='inner').sort_values(by='cost_per_person',ascending=True)\n",
    "best_value=best_value.rename(columns={'count': 'restaurants'})\n",
    "\n",
    "print(f'\\nBest Value for Money')\n",
    "print(\"=\"*80,'\\n')\n",
    "print(best_value.loc[(best_value['cost_per_person'] < 1000) & (best_value['restaurants'] > 5),\n",
    "      ['cost_per_person','restaurants']].to_markdown(),'\\n') # restaurants > 5 for more options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
